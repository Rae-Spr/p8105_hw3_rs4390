---
title: "p8105_hw3_rs4390"
author: "Rae Spriggs"
date: "2022-10-07"
output: github_document
---

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(dplyr)
library(patchwork)
knitr::opts_chunk$set(fig.width=12, fig.height=8) 
```

# Problem 1 

```{r}
library(p8105.datasets)
data("instacart")
```

## Dataset description
The `instacart` dataset contains `r nrow(instacart)` observations of individual products from Instacart orders. There are `r ncol(instacart)` total variables that detail the order information, product information, and user ID as seen below: 

* `order_id`: order identifier
* `product_id`: product identifier
* `add_to_cart_order`: order in which each product was added to cart
* `reordered`: 1 if this product has been ordered by this user in the past, 0 otherwise
* `user_id`: customer identifier
* `eval_set`: which evaluation set this order belongs in 
* `order_number`: the order sequence number for this user (1=first, n=nth)
* `order_dow`: the day of the week on which the order was placed
* `order_hour_of_day`: the hour of the day on which the order was placed
* `days_since_prior_order`: days since the last order, capped at 30, NA if order_number=1
* `product_name`: name of the product
* `aisle_id`: aisle identifier
* `department_id`: department identifier
* `aisle`: the name of the aisle
* `department`: the name of the department

For example, observation #417 (row 417 in `instacart`) details the ordering of red peppers, which were found in the fresh vegetables `aisle` in the produce `department`. This product was added to the cart 16th (out of 17 total items). The order was placed in the 17th hour of the day, and it had been at least 30 days since `user_id` 163023's last order. 

## How many aisles are there, and which aisles are the most items ordered from? 
```{r, message=FALSE, warning=FALSE}
aisles_distinct = instacart %>% 
  distinct(aisle)

most_ordered = instacart %>% 
  group_by(aisle, aisle_id) %>% 
  summarize(n_obs = n())
  
```

There are 134 aisles. The fresh vegetables aisle (aisle_id 83) and fresh fruits aisle (aisle_id 24) have the most items ordered with n being > 150000 each. 

## Making a plot for items ordered 
```{r, message=FALSE, warning=FALSE}
grouped = instacart %>% 
  group_by(aisle) %>% 
  summarize(aisle_count = n()) %>% 
  filter(aisle_count > 10000)

  ggplot(grouped, aes(x = (reorder(aisle, aisle_count)), y = aisle_count)) +
    geom_bar(stat = "identity") + 
      labs(
    x = "Aisle",
    y = "Number of Items Purchased",
    title = "Barplot of the most popular Instacart aisles") + 
    viridis::scale_color_viridis(
    name = "Aisle", 
    discrete = TRUE) + 
    coord_flip()
```

## Table for most popular items in three aisles 

```{r, message=FALSE, warning=FALSE}
three_aisles = instacart %>% 
  group_by(aisle, product_name) %>% 
  summarize(aisle_count = n()) %>% 
  filter(aisle == 'baking ingredients' | aisle == 'dog food care' | aisle == 'packaged vegetables fruits') %>% 
  arrange(desc(aisle_count)) %>% 
  slice(1:3) 

three_aisles
```

## Mean hour of day

```{r, message=FALSE, warning=FALSE}
mean_hour = instacart %>% 
  group_by(product_name, order_dow, order_hour_of_day) %>% 
  mutate(order_dow = recode(order_dow, `0` = "Sun", `1` = "Mon", `2` = "Tue", `3` = "Wed", `4` = "Thu", `5` = "Fri", `6` = "Sat")) %>% 
  filter(product_name == 'Pink Lady Apples' | product_name == 'Coffee Ice Cream') %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour_of_day = mean(order_hour_of_day, na.rm = TRUE)) %>% 
  pivot_wider(
    names_from = 'order_dow',
    values_from = 'mean_hour_of_day'
  ) %>% 
  select('Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat')

mean_hour
  
```

# Problem 2 

```{r, message = FALSE, warning = FALSE}
accel_data = read_csv('data/accel_data.csv') %>% 
  janitor:: clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440, 
    names_to = 'minutes', 
    values_to = 'count', 
    names_prefix = 'activity_') %>% 
  mutate(day_type = recode(day, "Monday" = "weekday", "Tuesday" = "weekday", "Wednesday" = "weekday", "Thursday" = "weekday", "Friday" = "weekday", "Saturday" = "weekend", "Sunday" = "weekend")) %>% 
  mutate(day = factor(day, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")), day_type = factor(day_type)) %>% 
  mutate_at(c('minutes'), as.numeric)
```

## Dataset description 

The accel_data dataset contains `r nrow(accel_data)` observations of activity values over a 24 hour period for the 63 year-old male being measured over 35 days. There are `r ncol(accel_data)` total variables that detail each minute and the `week` it was measured, the `day` of the week, the `day_id` of the study out of 35 days, whether it was a weekday or weekend (`day_type`), and the `count` which is the activity value measured at that minute. The resulting dataset has dimensions described above, which are 50400 rows x 6 columns.

## Total activity for each day 

```{r, message=FALSE, warning = FALSE}
total_activity = 
  accel_data %>% 
  group_by(day) %>% 
  summarize(total_activity = sum(count))

total_activity
```

Wednesdays, Thursdays, and Fridays have the highest activity values out of all the days of the week. Saturday has the lowest activity values. 

## Plot of 24 hour activity time on each day 

```{r, message=FALSE, warning= FALSE}
accel_data %>%  
  group_by(day, minutes) %>% 
  ggplot(aes(x = minutes, y = count, color = day)) + 
  geom_point(alpha=0.3) + 
  theme(axis.text.x = element_text(angle = 45)) +
  scale_x_continuous(breaks=seq(from = 0, to = 1440, by = 60)) + 
  labs(
    x = "Minute of day",
    y = "Activity value",
    title = "Scatterplot of 24 hour activity period by day of week")
```

As we see in the scatterplot, majority of the activity values (of whatever health data was captured for the patient) over a 24 hour period during the 35 days of observations fall below 2500. There are four distinct peaks where the activity values are higher than normal. The first peak occurs around minute 420,  which is around hour 7 out of 24. This spike in activity is associated with Thursdays, one of the days with higher activity values generally. The second peak occurs between minute 540 and 78, so between 9am and 1pm. These higher values are associated with Fridays and Sundays. The third peak occurs between minute 960 and 1020, so between 4 and 5pm. This peak of higher values is associated with Saturdays and Sundays, interesting because Saturday has the lowest activity values on average. The final peak occurs between minute 1140 and 1320, which is between 7-10pm. These higher activity values are associated mostly with Fridays and Wednesdays. This makes sense because Fridays and Wednesdays have higher activity values generally. 


# Problem 3 

```{r}
library(p8105.datasets)
data("ny_noaa") 

ny_noaa_tidy = ny_noaa %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month", "day"), sep = "-", convert = TRUE) %>% 
  mutate(
    year = as.numeric(year), 
    month = as.numeric(month), 
    day = as.numeric(day), 
    prcp = as.numeric(prcp), 
    snow = as.numeric(snow), 
    snwd = as.numeric(snwd), 
    tmax = as.numeric(tmax), 
    tmin = as.numeric(tmin), 
    prcp = prcp/10, 
    tmax = tmax/10, 
    tmin = tmin/10)
```
 
## Dataset description
 
The ny_noaa_tidy dataset contains `r nrow(ny_noaa_tidy)` daily observations of weather data captured at NY weather stations over the time period of Jan 1981 - Dec 2010. There are `r ncol(ny_noaa_tidy)` total variables that detail the date of obseravtion (`year`, `month`, and `day`), the weather station `id`, and levels of precipitation (`prcp`), `snow`, and snow depth (`snwd`) in mm, and maximum and minimum temperatures (`tmax` and `tmin`). The resulting dataset has dimensions described above, which are 2595176 rows x 9 columns. About half of the stations only report precipitation data and the record length varies across stations. We should use caution when conducting comparative analysis and only compare for observations with all relevant data (i.e. drop NA's). 

## Most common snowfall values 

```{r}
n_snow_table = 
  ny_noaa_tidy %>% 
    group_by(snow) %>%
  distinct() %>% 
  summarize(n_snow = n())
```
 
The most common snowfall value is 0 mm of snow because it doesn't snow most days of the year in New York. The next most common observation is N/A, which makes sense because about half of the weather stations only capture precipitation data. Of actual snowfall observations > 0 mm, 25 mm is the most common in our dataset. 
 
## Avg max temperature plot (Jan vs. July)

```{r, message=FALSE, warning= FALSE}
avg_tmax = 
  ny_noaa_tidy %>% 
  group_by(month, year, id) %>% 
  filter(month == '1' | month == '7') %>% 
  mutate(month = recode(month, `1` = "January", `7` = "July")) %>% 
  summarize(
    mean_tmax = mean(tmax, na.rm = TRUE))
  
  avg_tmax %>% 
    ggplot(aes(x = year, y = mean_tmax, group = id)) + 
    geom_line(alpha=0.3) + 
    facet_grid(. ~ month) + 
    labs(
    x = "Year",
    y = "Average Maximum Temp (C)",
    title = "Lineplot of avg max temperatures in January and July")
```

When looking at the lineplots, it is easy to see that July has higher average maximum temperatures than January does between the  years 1981 - 2010. The lineplots for Janurary and July indicate a few outliers on each, with more outliers being at the lower end of the range. Most values are clustered within a certain range of degrees C, with the range being relatively larger for January than for July. 

## Patchwork plot: 1) Tmax vs. tmin and 2) NY snowfall between 0-100 mm

```{r, message=FALSE, warning= FALSE}
temps = ny_noaa_tidy %>% 
  group_by(year, month, day) %>% 
  drop_na(tmax, tmin)

hex_plot = temps %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_hex() + 
  labs(
    x = "Minimum Temp (C)",
    y = "Maximum Temp (C)",
    title = "Hexogram plot of all NY weather observations 1981-2010 (tmax vs. tmin)")

snowfall = 
  ny_noaa_tidy %>% 
  group_by(snow, year) %>% 
  filter(between(snow, 0, 100)) %>% 
  drop_na(snow) %>% 
  mutate(year = as.character(year))

snowfall_plot = 
  snowfall %>% 
  ggplot(aes(x = year, y = snow)) +
  geom_violin() + 
  theme(axis.text.x = element_text(angle = 90)) + 
  labs(
    x = "Year",
    y = "Snowfall (mm)",
    title = "Violin plot of NY snowfall observations between 0-100mm")

hex_plot + snowfall_plot
```

